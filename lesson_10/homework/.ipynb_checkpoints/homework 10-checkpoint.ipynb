{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f20e91dc-f2af-4982-8c8a-844b3e8f4324",
   "metadata": {},
   "source": [
    "## HOMEWORK 10\n",
    "\n",
    "We are going to use and compare three different trackers and compare the results. Plus try to use YOLO for detecting drone as aeroplane.\n",
    "\n",
    "In our script, we want to compare three types of detectors built into opencv.\n",
    "The diagram of the script is given below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e9fc0c-cbd1-4990-a0b8-9ab010ffa14f",
   "metadata": {},
   "source": [
    "![SVG Image](hw_tracking_opencv_v10.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea6c6ae-8ba3-4fb5-bf96-059718d412ff",
   "metadata": {},
   "source": [
    "As you can see in the main function of the script there are simply three sections for various videos with drone:\n",
    "1. Tracking + detection when tracking disappears.\n",
    "2. Just traÑking\n",
    "3. But just detection.\n",
    "\n",
    "An initial drone bounding box is manually defined for each video.\n",
    "\n",
    "As a detector, I took a simple example of using the yolo library to classify objects in a picture, and converted it for convenience into a module with the function of searching for a drone in a picture. In my case, it looks for the largest bounding box in the image that belongs to the *aeroplane* class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc818b0-20ad-44e3-85a4-525bdd0ad2fb",
   "metadata": {},
   "source": [
    "### Code of detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73b7e73-ac5e-4bdf-bc0d-139859640c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Paths to the YOLO files\n",
    "config_path = 'yolo/yolov3.cfg'\n",
    "weights_path = 'yolo/yolov3.weights'\n",
    "names_path = 'yolo/coco.names'\n",
    "\n",
    "# Load class names\n",
    "classes = open(names_path).read().strip().split('\\n')\n",
    "\n",
    "# Check if the class \"aeroplane\" is in the list of classes\n",
    "if \"aeroplane\" not in classes:\n",
    "    print(\"Error: 'aeroplane' class not found in the provided names file.\")\n",
    "    exit()\n",
    "\n",
    "aeroplane_class_id = classes.index(\"aeroplane\")\n",
    "\n",
    "# Load YOLO network\n",
    "net = cv2.dnn.readNetFromDarknet(config_path, weights_path)\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "\n",
    "# Get the output layer names\n",
    "ln = net.getUnconnectedOutLayersNames()\n",
    "\n",
    "def detect_largest_aeroplane(img):\n",
    "    if img is None:\n",
    "        print(\"Error: Could not open or find the image.\")\n",
    "        return None\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    # Prepare the image for detection\n",
    "    blob = cv2.dnn.blobFromImage(img, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "\n",
    "    # Perform detection\n",
    "    t0 = time.time()\n",
    "    outputs = net.forward(ln)\n",
    "    t = time.time()\n",
    "    print(f'It took {t - t0:.3f} seconds to process the image.')\n",
    "\n",
    "    # Process detections\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    for output in outputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if class_id == aeroplane_class_id and confidence > 0.5:\n",
    "                box = detection[:4] * np.array([w, h, w, h])\n",
    "                (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "                x = int(centerX - (width / 2))\n",
    "                y = int(centerY - (height / 2))\n",
    "                boxes.append([x, y, int(width), int(height)])\n",
    "                confidences.append(float(confidence))\n",
    "\n",
    "    # Apply non-maxima suppression to filter out weak detections\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "    # Find the largest bounding box\n",
    "    if len(indices) > 0:\n",
    "        largest_box = None\n",
    "        largest_area = 0\n",
    "        for i in indices.flatten():\n",
    "            (x, y, w, h) = boxes[i]\n",
    "            area = w * h\n",
    "            if area > largest_area:\n",
    "                largest_area = area\n",
    "                largest_box = (x, y, w, h)\n",
    "\n",
    "        if largest_box:\n",
    "            (x, y, w, h) = largest_box\n",
    "            # Crop the image to the largest bounding box\n",
    "##            cropped_img = img[y:y + h, x:x + w]\n",
    "            return largest_box\n",
    "\n",
    "    return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    img_path = 'drone.png'\n",
    "    # Load the image\n",
    "    img = cv2.imread(img_path)\n",
    "    cropped_img = detect_largest_aeroplane(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b04cc3-d61e-4aa0-ab01-19b56f236bc7",
   "metadata": {},
   "source": [
    "### Code of main script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97c0c4e-7b37-4609-ae92-0ca87c8acdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import cv2\n",
    "from yolodetect import detect_largest_aeroplane\n",
    "\n",
    "FRAMES = 65\n",
    "COLOR = (0, 0, 255)\n",
    "FONT_SCALE = 3.0\n",
    "THICKNESS = 5\n",
    "K = 0.7\n",
    "H = int(1080*K)\n",
    "W = int(1920*K)\n",
    "RESIZE_DIMS = (W, H)\n",
    "MODE_TEXT_POS = (3840-1650,2160-200, )\n",
    "\n",
    "\n",
    "def create_tracker(tracker_type):\n",
    "    \"\"\"\n",
    "    Create an OpenCV tracker based on the given type.\n",
    "    \"\"\"\n",
    "    if tracker_type == 'MIL':\n",
    "        return cv2.legacy.TrackerMIL_create()\n",
    "    elif tracker_type == 'KCF':\n",
    "        return cv2.legacy.TrackerKCF_create()\n",
    "    elif tracker_type == \"CSRT\":\n",
    "        return cv2.legacy.TrackerCSRT_create()\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown tracker type: {tracker_type}\")\n",
    "\n",
    "def initialize_tracker(cap, tracker, x1, y1, width, height):\n",
    "    \"\"\"\n",
    "    Initialize the tracker with the first frame from the video capture.\n",
    "    \"\"\"\n",
    "    ret, img = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        exit()\n",
    "\n",
    "    bbox = (x1, y1, width, height)\n",
    "    tracker.init(img, bbox)\n",
    "\n",
    "    return img, bbox\n",
    "\n",
    "def draw_rectangle(img, bbox, color=(0, 255, 0), thickness=2):\n",
    "    \"\"\"\n",
    "    Draw a rectangle around the tracked object.\n",
    "    \"\"\"\n",
    "    x1, y1 = int(bbox[0]), int(bbox[1])\n",
    "    width, height = int(bbox[2]), int(bbox[3])\n",
    "    cv2.rectangle(img, (x1, y1), (x1 + width, y1 + height), color, thickness)\n",
    "\n",
    "def process_frame_with_tracker(tracker, img, tracker_type):\n",
    "    \"\"\"\n",
    "    Process the frame using the tracker and update the bounding box.\n",
    "    \"\"\"\n",
    "    ok, bbox = tracker.update(img)\n",
    "    if ok:\n",
    "        draw_rectangle(img, bbox)\n",
    "        x, y, w, h = [int(v) for v in bbox]\n",
    "        cv2.putText(img, tracker_type, (x + w, y + h), cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE, COLOR, THICKNESS)\n",
    "    return ok\n",
    "\n",
    "def process_frame_with_detector(img):\n",
    "    \"\"\"\n",
    "    Process the frame using the YOLO detector to find the largest aeroplane.\n",
    "    \"\"\"\n",
    "    bbox = detect_largest_aeroplane(img)\n",
    "    if bbox:\n",
    "        draw_rectangle(img, bbox)            \n",
    "        x, y, w, h = bbox\n",
    "        cv2.putText(img, \"AERO\", (x + w, y + h), cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE, COLOR, THICKNESS)\n",
    "    return bbox\n",
    "\n",
    "def display_frame(img, resize_dimensions=RESIZE_DIMS):\n",
    "    \"\"\"\n",
    "    Display the frame with resized dimensions.\n",
    "    \"\"\"\n",
    "    stretch_near = cv2.resize(img, resize_dimensions, interpolation=cv2.INTER_LINEAR)\n",
    "    cv2.imshow('frame', stretch_near)\n",
    "\n",
    "def detecting(video_path):\n",
    "    \"\"\"\n",
    "    detecting function to run the detector on the video.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Cannot open video\")\n",
    "        exit()\n",
    "\n",
    "    tracker_frame_counter = FRAMES\n",
    "    while tracker_frame_counter > 0:\n",
    "        ret, img = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "            break\n",
    "\n",
    "        bbox = process_frame_with_detector(img)\n",
    "        if not bbox:\n",
    "            cv2.putText(img, \"Detecting FAIL\", (100, 150), cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE, COLOR, THICKNESS)\n",
    "        else:\n",
    "            cv2.putText(img, \"Detecting SUCCESS\", (100, 150), cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE, COLOR, THICKNESS)\n",
    "        cv2.putText(img, \"Working only DETECTING\", MODE_TEXT_POS, cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE, COLOR, THICKNESS)\n",
    "        display_frame(img)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        tracker_frame_counter -= 1\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def tracking(video_path, tracker_type, x1, y1, x2, y2):\n",
    "    \"\"\"\n",
    "    tracking function to run the tracker on the video.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Cannot open video\")\n",
    "        exit()\n",
    "    \n",
    "    width, height = x2 - x1, y2 - y1\n",
    "    tracker = create_tracker(tracker_type)\n",
    "    img, bbox = initialize_tracker(cap, tracker, x1, y1, width, height)\n",
    "\n",
    "    tracker_frame_counter = FRAMES\n",
    "    while tracker_frame_counter > 0:\n",
    "        ret, img = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "            break\n",
    "\n",
    "        ok = process_frame_with_tracker(tracker, img, tracker_type)\n",
    "        if not ok:\n",
    "            cv2.putText(img, \"Tracking FAIL\", (100, 100), cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE, COLOR, THICKNESS)\n",
    "        else:\n",
    "            cv2.putText(img, \"Tracking SUCCESS\", (100, 100), cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE, COLOR, THICKNESS)\n",
    "        cv2.putText(img, \"Working only TRACKING\", MODE_TEXT_POS, cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE, COLOR, THICKNESS)\n",
    "        display_frame(img)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        tracker_frame_counter -= 1\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def tracking_detecting(video_path, tracker_type, x1, y1, x2, y2):\n",
    "    \"\"\"\n",
    "    tracking_detecting function to run the tracker on the video and help it with yolo detecting.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Cannot open video\")\n",
    "        exit()\n",
    "    \n",
    "    width, height = x2 - x1, y2 - y1\n",
    "    tracker = create_tracker(tracker_type)\n",
    "    img, bbox = initialize_tracker(cap, tracker, x1, y1, width, height)\n",
    "\n",
    "    tracker_frame_counter = FRAMES\n",
    "    while tracker_frame_counter > 0:\n",
    "        ret, img = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "            break\n",
    "\n",
    "        ok = process_frame_with_tracker(tracker, img, tracker_type)\n",
    "        if ok:\n",
    "            cv2.putText(img, \"Tracking SUCCESS\", (100, 100), cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE, COLOR, THICKNESS)\n",
    "        else:\n",
    "            cv2.putText(img, \"Tracking FAIL\", (100, 100), cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE, COLOR, THICKNESS)\n",
    "            bbox = process_frame_with_detector(img)\n",
    "            if not bbox:\n",
    "                cv2.putText(img, \"Detecting FAIL\", (100, 180), cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE, COLOR, THICKNESS)\n",
    "            else:\n",
    "                tracker = create_tracker(tracker_type)\n",
    "                tracker.init(img, bbox)\n",
    "                cv2.putText(img, \"Detecting SUCCESS\", (100, 180), cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE, COLOR, THICKNESS)\n",
    "        cv2.putText(img, \"Working only TRACKING+DETECTING\", MODE_TEXT_POS, cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE, COLOR, THICKNESS)\n",
    "        display_frame(img)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        tracker_frame_counter -= 1\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    video_paths = [\"dron1.mov\", \"dron2.mp4\", \"dron3.mov\", \"dron4.mov\"]\n",
    "    tracker_types = ['KCF', 'CSRT', 'MIL']\n",
    "    rects = [\n",
    "        (1377, 1499, 1479, 1557),\n",
    "        (675, 1445, 918, 1572),\n",
    "##        (685, 1450, 908, 1562),\n",
    "        (1347, 1817, 1443, 1876),\n",
    "##        (1357, 1827, 1433, 1866),\n",
    "        (2439, 1455, 2579, 1510)\n",
    "    ]\n",
    "    start_from = 0\n",
    "\n",
    "    # USE TRACKING AND IF IT NEEDS TRY DETECT\n",
    "    for video_path, rect in zip(video_paths[start_from:], rects[start_from:]):\n",
    "        x1, y1, x2, y2 = rect\n",
    "        for tracker_type in tracker_types:\n",
    "            tracking_detecting(video_path, tracker_type, x1, y1, x2, y2)  \n",
    "\n",
    "    \n",
    "    # USE ONLY TRACKING\n",
    "    for video_path, rect in zip(video_paths[start_from:], rects[start_from:]):\n",
    "        x1, y1, x2, y2 = rect\n",
    "        for tracker_type in tracker_types:\n",
    "            tracking(video_path, tracker_type, x1, y1, x2, y2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #JUST YOLO AEROPLANE DETECTOR\n",
    "    for video_path in video_paths[start_from:]:\n",
    "        detecting(video_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634ffe5f-94cb-4fa8-84e5-5b0a0136402e",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "You can see the result of the work on the video\n",
    "https://youtu.be/wTKhB4wHP2s\n",
    "The main thing is that even the most stable tracking is lost after 10-20 frames. It is even worse that tracking can think that it is not wrong when it has long since lost the drone.\n",
    "That is, the system must work together with the detector. The detector must be trained on drones. The Yolo detector gave negative results even against a clear sky. \n",
    "\n",
    "To my taste, the best result was given by CSRT, but again, without a reliable detector, its accuracy for tracking is not enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48403828-7a82-4479-8d8b-16461cfc45c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
