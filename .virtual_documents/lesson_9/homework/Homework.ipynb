





import dlib
# Let's load the detector

# Detect faces, see http://dlib.net/face_detector.py.html
# 1 --> upsampling factor
import numpy as np
from ipywidgets import Video
from IPython.display import display
import cv2
import math










detector = dlib.get_frontal_face_detector()

def rect_to_bb(rect):
    # Dlib rect --> OpenCV rect
    x = rect.left()
    y = rect.top()
    w = rect.right() - x
    h = rect.bottom() - y

    return (x, y, w, h)

def draw_rectangles(img_rgb):
    rects = detector(img_rgb, 1)

# print('Number of detected faces:', len(rects))
# print(rects)
# print(rects[0].left)
    # Draw rectangle around each face
    result_dlib = np.copy(img_rgb)
    # faces_dlib_img = []
    for rect in rects:    
        # Draw rectangle around the face
        x, y, w, h = rect_to_bb(rect)
        # print(x, y, w, h)
        cv2.rectangle(result_dlib, (x, y), (x+w, y+h), (0, 255, 0), 3)
        # faces_dlib_img.append(img_rgb[y:y+h, x:x+w, :])
    return img_rgb


# Function to draw on frames
def draw_on_frame(frame):
    # Convert image to gray scale
    # gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY) 
    
    return draw_rectangles(frame)

# Open the original video
cap = cv2.VideoCapture('../data/stupid_faces.mp4')

# Get video properties
fps = cap.get(cv2.CAP_PROP_FPS)
width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Define the codec

# Create a VideoWriter object to write the video
out = cv2.VideoWriter('../data/stupid_faces_out.mp4', fourcc, fps, (width, height))

# Process the video frames
while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break
    # Draw on frame
    frame = draw_on_frame(frame)
    # Write the frame to the output video
    out.write(frame)


# Release resources
cap.release()
out.release()

# Display the modified video in Jupyter Lab
video_widget = Video.from_file('../data/output_modified.mp4')
display(video_widget)












