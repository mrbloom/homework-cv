


import cv2
import numpy as np
from matplotlib import pyplot as plt
plt.rcParams['figure.figsize'] = [15, 10]





# Initialize detector
detector = cv2.FaceDetectorYN.create("./data/datasets/face_detection_yunet_2023mar.onnx", "", (320, 320))
print(detector)
# Read image
source = cv2.imread('./data/zelensky.jpg')
source = cv2.cvtColor(source, cv2.COLOR_BGR2RGB)
rows, cols, _ = source.shape
print(rows,cols)
# Get image shape
img_W = int(source.shape[1])
img_H = int(source.shape[0])

# Set input size
detector.setInputSize((cols, rows))

# Run detector
faces_src = detector.detect(source)
assert faces_src[0]





# Show detected faces on image
result = np.copy(source)
faces_src_img = []

for face in faces_src[1]:
    # Draw box
    x1, y1, w, h = face[0:4]
    faces_src_img.append(source[int(y1):int(y1+h), int(x1):int(x1+h), :])
    cv2.rectangle(result, (int(x1), int(y1)), (int(x1+w), int(y1+h)), color=(0, 255, 0), thickness=2)    

    # Draw landmarks
    for idx in range(4, len(face)-1, 2):        
        cv2.circle(result, (int(face[idx]), int(face[idx+1])), radius=4, color=(0, 255, 0), thickness=-1)            

plt.imshow(result)





target = cv2.imread('data/eu_summit.jpg')
target = cv2.cvtColor(target, cv2.COLOR_BGR2RGB)
rows, cols, _ = target.shape

detector.setInputSize((cols, rows))
faces_dst = detector.detect(target)
assert faces_dst[0]


result = np.copy(target)
faces_dst_img = []


for face in faces_dst[1]:    
    x1, y1, w, h = face[0:4]
    faces_dst_img.append(target[int(y1):int(y1+h), int(x1):int(x1+h), :])
    cv2.rectangle(result, (int(x1), int(y1)), (int(x1+w), int(y1+h)), color=(0, 255, 0), thickness=2)
    
    # Draw landmarks
    for idx in range(4, len(face)-1, 2):        
        cv2.circle(result, (int(face[idx]), int(face[idx+1])), radius=2, color=(0, 255, 0), thickness=-1)            
    
plt.imshow(result)








recognizer = cv2.FaceRecognizerSF.create("./data/datasets/face_recognition_sface_2021dec.onnx", "")


# Align source face
faces_src_agn = recognizer.alignCrop(source, faces_src[1][0])

plt.subplot(121), plt.imshow(faces_src_img[0])
plt.subplot(122), plt.imshow(faces_src_agn)


# Align target faces

faces_dst_agn = [recognizer.alignCrop(target, face) for face in faces_dst[1]]

plt.rcParams['figure.figsize'] = [15, 5]
for idx, faces in enumerate(zip(faces_dst_img, faces_dst_agn)):
    plt.subplot(2,8,idx+1), plt.imshow(faces[0]), plt.axis(False)
    plt.subplot(2,8,8+idx+1), plt.imshow(faces[1]), plt.axis(False)





# Extract features
feat_src = recognizer.feature(faces_src_agn)
feats_dst = [recognizer.feature(face) for face in faces_dst_agn]





scores = []
for feat_dst in feats_dst:
    score_ = recognizer.match(feat_src, feat_dst, cv2.FaceRecognizerSF_FR_COSINE)
#     score_ = recognizer.match(feat_src, feat_dst, cv2.FaceRecognizerSF_FR_NORM_L2)

    scores.append(score_)

scores


result = np.copy(target)
plt.rcParams['figure.figsize'] = [15, 10]

match = faces_dst[1][np.argmax(scores)]
x1, y1, w, h = match[0:4]
cv2.rectangle(result, (int(x1), int(y1)), (int(x1+w), int(y1+h)), color=(0, 255, 0), thickness=2)
    
plt.imshow(result)



